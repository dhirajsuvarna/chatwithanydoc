{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_MODEL_NAME=\"all-MiniLM-L6-v2\"\n",
    "PERSIST_DIRECTORY= r\"F:\\projects\\gpt\\chatwithanydoc\\web_app\\vectorstore_db\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\anaconda3\\envs\\privategpt\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDINGS_MODEL_NAME)\n",
    "db = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings) #, client_settings=CHROMA_SETTINGS)\n",
    "db.get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "model_path = r\"C:\\gpt4all\\models\\guanaco-7B.ggmlv3.q4_1.bin\"\n",
    "llm = LlamaCpp(model_path=model_path, n_ctx=1000, callbacks=[StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhiraj: 10000370858_02-303002-TW-MO.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: C:\\drive\\projects\\llm_dev\\chatwithanydoc\\chainlit_app\\vectorstore_db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhiraj: [{'sources': '10000370858_02-303002-TW-MO.pdf'}, {'sources': '10000370858_02-303002-TW-MO.pdf'}, {'sources': '10000370858_02-303002-TW-MO.pdf'}, {'sources': '10000370858_02-303002-TW-MO.pdf'}, {'sources': '10000370858_02-303002-TW-MO.pdf'}, {'sources': '10000370858_02-303002-TW-MO.pdf'}, {'sources': '10000370858_02-303002-TW-MO.pdf'}, {'sources': '10000370858_02-303002-TW-MO.pdf'}, {'sources': '10000370858_02-303002-TW-MO.pdf'}, {'sources': '10000370858_02-303002-TW-MO.pdf'}, {'sources': '10000370858_02-303002-TW-MO.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "persist_dir = r\"C:\\drive\\projects\\llm_dev\\chatwithanydoc\\chainlit_app\\vectorstore_db\"\n",
    "filename = \"10000370858_02-303002-TW-MO.pdf\"\n",
    "\n",
    "def are_embeddings_present(iFileName, iEmbeddings):\n",
    "    print(f\"dhiraj: {iFileName}\")\n",
    "    db = Chroma(persist_directory=persist_dir, embedding_function=iEmbeddings) #, client_settings=CHROMA_SETTINGS)\n",
    "    collection = db.get()\n",
    "    isEmbeddingPresent = False\n",
    "    print(f\"dhiraj: {collection['metadatas']}\")\n",
    "    for metadata in collection['metadatas']:\n",
    "        if metadata['sources'] == iFileName:\n",
    "            isEmbeddingPresent = True\n",
    "            break\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "are_embeddings_present(filename, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privategpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b99fcfedf2f6577f03830249f5c4b45f3f67966246d124081a3ac182afded511"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
